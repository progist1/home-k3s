apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: zfs-rules
  namespace: monitoring
  labels:
    release: kube-prometheus-stack
spec:
  groups:
  - name: zfs-pool-state
    interval: 30s
    rules:
    # ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð»ÐµÑ€Ñ‚: Ð¿ÑƒÐ» ÐÐ• online
    - alert: ZFSPoolNotOnline
      expr: |
        # Ð˜Ñ‰ÐµÐ¼ Ð¿ÑƒÐ»Ñ‹, Ð³Ð´Ðµ online=0, Ð½Ð¾ ÐµÑÑ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ = 1
        (
          node_zfs_zpool_state{state="online"} == 0
          and on(instance, zpool) (
            max by (instance, zpool) (node_zfs_zpool_state{state=~"degraded|faulted|unavail|removed"}) == 1
          )
        )
        * on(instance, zpool) group_left(state)
          max by (instance, zpool, state) (node_zfs_zpool_state{state=~"degraded|faulted|unavail|removed"} == 1)
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "ZFS pool {{ $labels.zpool }} is {{ $labels.state }} on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.zpool }}
          **Status:** {{ $labels.state | title }}
          **Host:** {{ $labels.hostname }}
          **Action:** âš ï¸ Immediate attention required!

  - name: zfs-capacity
    interval: 30s
    rules:
    # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿ÑƒÐ»Ð° (>80%)
    - alert: ZFSPoolCapacityHigh
      expr: |
        (
          (zfs_pool_allocated_bytes / zfs_pool_size_bytes) * 100 > 80
        )
        * on(instance, pool) group_left
          zfs_pool_size_bytes
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "ZFS pool {{ $labels.pool }} is {{ $value | humanize }}% full on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.pool }}
          **Used:** {{ $value | humanize }}%
          **Allocated:** {{ printf "%.2f TiB" (mulf $value 0.01) }}
          **Host:** {{ $labels.hostname }}
          **Action:** ðŸ—„ï¸ Free up space or expand pool

  - name: zfs-capacity-critical
    interval: 30s
    rules:
    # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿ÑƒÐ»Ð° (>90%)
    - alert: ZFSPoolCapacityHigh
      expr: |
        (
          (zfs_pool_allocated_bytes / zfs_pool_size_bytes) * 100 > 90
        )
        * on(instance, pool) group_left
          zfs_pool_size_bytes
      for: 15m
      labels:
        severity: critical
      annotations:
        summary: "ZFS pool {{ $labels.pool }} is {{ $value | humanize }}% full on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.pool }}
          **Used:** {{ $value | humanize }}%
          **Allocated:** {{ printf "%.2f TiB" (mulf $value 0.01) }}
          **Host:** {{ $labels.hostname }}
          **Action:** ðŸ—„ï¸ Immediate free up space or expand pool

  - name: zfs-performance
    interval: 30s
    rules:
    # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð¿ÑƒÐ»Ð° (>60%)
    - alert: ZFSPoolFragmentationHigh
      expr: |
        (
          zfs_pool_fragmentation_ratio * 100 > 60
        )
        * on(instance, pool) group_left
          zfs_pool_size_bytes
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "ZFS pool {{ $labels.pool }} fragmentation high on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.pool }}
          **Fragmentation:** {{ $value | humanize }}%
          **Host:** {{ $labels.hostname }}
          **Action:** ðŸ’¾ Consider pool scrub and balance

    # ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ (ratio < 1.0)
    - alert: ZFSDeduplicationIssue
      expr: |
        (
          zfs_pool_deduplication_ratio < 1.0
        )
        * on(instance, pool) group_left
          zfs_pool_size_bytes
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "ZFS pool {{ $labels.pool }} dedup ratio abnormal on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.pool }}
          **Deduplication ratio:** {{ $value }}
          **Host:** {{ $labels.hostname }}
          **Issue:** ðŸ§¹ Deduplication table may be corrupted

  - name: zfs-health-met
    interval: 30s
    rules:
    # Health Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° Ð¾Ñ‚ zfs-exporter (ÐµÑÐ»Ð¸ != 0)
    - alert: ZFSPoolHealthBad
      expr: |
        (
          zfs_pool_health != 0
        )
        * on(instance, pool) group_left
          zfs_pool_size_bytes
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "ZFS pool {{ $labels.pool }} health bad on {{ $labels.hostname }}"
        description: |
          **Pool:** {{ $labels.pool }}
          **Health value:** {{ $value }}
          **Host:** {{ $labels.hostname }}
          **Action:** ðŸš¨ Check `zpool status` immediately!